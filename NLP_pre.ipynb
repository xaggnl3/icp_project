{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/mengxiangyong/opt/anaconda3/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: regex in /Users/mengxiangyong/opt/anaconda3/lib/python3.8/site-packages (from nltk) (2020.10.15)\n",
      "Requirement already satisfied: tqdm in /Users/mengxiangyong/opt/anaconda3/lib/python3.8/site-packages (from nltk) (4.50.2)\n",
      "Requirement already satisfied: joblib in /Users/mengxiangyong/opt/anaconda3/lib/python3.8/site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: click in /Users/mengxiangyong/opt/anaconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nltk.sent_tokenize(text) 对文本按照句子进行分割\n",
    "\n",
    "# nltk.word_tokenize(sent) 对句子进行分词\n",
    "\n",
    "# nltk.pos_tag(tokens)      tokens是句子分词后的结果，同样是句子级的标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python.com is very good website. We can learn a lot form it'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text='Python.com is very good website. We can learn a lot form it'\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python.com is very good website.', 'We can learn a lot form it']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens = nltk.sent_tokenize(text) #对文本按照句子进行分割\n",
    "sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "for i in sens:\n",
    "    words.append(nltk.word_tokenize(i))#对句子进行分词\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python.com', 'is', 'very', 'good', 'website', '.'],\n",
       " ['We', 'can', 'learn', 'a', 'lot', 'form', 'it']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CC 连词 and, or,but, if, while,although\n",
    "\n",
    "CD 数词 twenty-four, fourth, 1991,14:24\n",
    "\n",
    "DT 限定词 the, a, some, most,every, no\n",
    "\n",
    "EX 存在量词 there, there's\n",
    "\n",
    "FW 外来词 dolce, ersatz, esprit, quo,maitre\n",
    "\n",
    "IN 介词连词 on, of,at, with,by,into, under\n",
    "\n",
    "\n",
    "JJ 形容词 new,good, high, special, big, local\n",
    "\n",
    "JJR 比较级词语 bleaker braver breezier briefer brighter brisker\n",
    "\n",
    "\n",
    "JJS 最高级词语 calmest cheapest choicest classiest cleanest clearest\n",
    "\n",
    "LS 标记 A A. B B. C C. D E F First G H I J K\n",
    "\n",
    "MD 情态动词 can cannot could couldn't\n",
    "\n",
    "NN 名词 year,home, costs, time, education\n",
    "\n",
    "NNS 名词复数 undergraduates scotches\n",
    "\n",
    "NNP 专有名词 Alison,Africa,April,Washington\n",
    "\n",
    "NNPS 专有名词复数 Americans Americas Amharas Amityvilles\n",
    "\n",
    "PDT 前限定词 all both half many\n",
    "\n",
    "POS 所有格标记 ' 's\n",
    "\n",
    "PRP 人称代词 hers herself him himself hisself\n",
    "\n",
    "PRP$ 所有格 her his mine my our ours\n",
    "\n",
    "RB 副词 occasionally unabatingly maddeningly\n",
    "\n",
    "RBR 副词比较级 further gloomier grander\n",
    "\n",
    "RBS 副词最高级 best biggest bluntest earliest\n",
    "\n",
    "RP 虚词 aboard about across along apart\n",
    "\n",
    "SYM 符号 % & ' '' ''. ) )\n",
    "\n",
    "TO 词to to\n",
    "\n",
    "UH 感叹词 Goodbye Goody Gosh Wow\n",
    "\n",
    "VB 动词 ask assemble assess\n",
    "\n",
    "VBD 动词过去式 dipped pleaded swiped\n",
    "\n",
    "VBG 动词现在分词 telegraphing stirring focusing\n",
    "\n",
    "VBN 动词过去分词 multihulled dilapidated aerosolized\n",
    "\n",
    "VBP 动词现在式非第三人称时态 predominate wrap resort sue\n",
    "\n",
    "VBZ 动词现在式第三人称时态 bases reconstructs marks\n",
    "\n",
    "WDT Wh限定词 who,which,when,what,where,how\n",
    "\n",
    "WP WH代词 that what whatever\n",
    "\n",
    "WP$ WH代词所有格 whose\n",
    "\n",
    "WRB WH副词\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags=[]\n",
    "for i in words:\n",
    "    tags.append(nltk.pos_tag(i)) #tokens是句子分词后的结果，同样是句子级的标注  词性标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Python.com', 'NNP'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('very', 'RB'),\n",
       "  ('good', 'JJ'),\n",
       "  ('website', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('We', 'PRP'),\n",
       "  ('can', 'MD'),\n",
       "  ('learn', 'VB'),\n",
       "  ('a', 'DT'),\n",
       "  ('lot', 'NN'),\n",
       "  ('form', 'NN'),\n",
       "  ('it', 'PRP')]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Xi', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('chiarman', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('china', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('year', 'NN'),\n",
       " ('2013', 'CD'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = 'Xi is the chiarman of china in the year 2013.'\n",
    "tokens = nltk.word_tokenize(text1)\n",
    "tags = nltk.pos_tag(tokens)\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'love', 'nature', 'language', 'processing']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I love nature language processing\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT', '@', 'angelababy', ':', 'love', 'you', 'baby', '!', ':', 'D', 'http', ':', '//ah.love', '#', '168cm']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tweet = 'RT @angelababy: love you baby! :D http://ah.love #168cm'\n",
    "print(word_tokenize(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3种词根提取方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'owe'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer  \n",
    "porter_stemmer = PorterStemmer()  \n",
    "porter_stemmer.stem('maximum')  \n",
    "  \n",
    "porter_stemmer.stem('presumably')  \n",
    " \n",
    "porter_stemmer.stem('multiply')  \n",
    "  \n",
    "porter_stemmer.stem('provision')  \n",
    " \n",
    "porter_stemmer.stem('owed')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ow'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer  \n",
    "lancaster_stemmer = LancasterStemmer()  \n",
    "lancaster_stemmer.stem('maximum')  \n",
    " \n",
    "lancaster_stemmer.stem('presumably')  \n",
    "  \n",
    "lancaster_stemmer.stem('multiply')  \n",
    " \n",
    "lancaster_stemmer.stem('provision')  \n",
    "  \n",
    "lancaster_stemmer.stem('owed')  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multipli'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer  \n",
    "snowball_stemmer = SnowballStemmer('english')  \n",
    "snowball_stemmer.stem('maximum')  \n",
    " \n",
    "snowball_stemmer.stem('presumably')  \n",
    "  \n",
    "snowball_stemmer.stem('multiply')  \n",
    "\n",
    "snowball_stemmer.stem('provision')  \n",
    "\n",
    "#snowball_stemmer.stem('owed')  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 词性还原"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "wordnet_lemmatizer.lemmatize('dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer  \n",
    "from nltk.corpus import words  \n",
    "      \n",
    "wordlist = set(words.words())  \n",
    "wordnet_lemmatizer = WordNetLemmatizer()  \n",
    "      \n",
    "def max_match(text):  \n",
    "    pos2 = len(text)  \n",
    "    result = ''  \n",
    "    while len(text) > 0:         \n",
    "        word = wordnet_lemmatizer.lemmatize(text[0:pos2])  \n",
    "        if word in wordlist:  \n",
    "            result = result + text[0:pos2] + ' '  \n",
    "            text = text[pos2:]  \n",
    "            pos2 = len(text)  \n",
    "        else:  \n",
    "            pos2 = pos2-1                 \n",
    "    return result[0:-1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "they are birds\n"
     ]
    }
   ],
   "source": [
    "string = 'theyarebirds'  \n",
    "print(max_match(string))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
